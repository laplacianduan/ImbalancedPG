\relax 
\citation{ngai2011application}
\citation{wakefield2007disease}
\citation{wang2010click}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{minsker2014robust,srivastava2015wasp,conrad2015accelerating}
\citation{roberts2004general,meyn2012markov}
\citation{rajaratnam2015mcmc}
\citation{hairer2011asymptotic}
\citation{hairer2014spectral}
\citation{johndrow2016inefficiency}
\citation{albert1993bayesian}
\citation{polson2013bayesian}
\citation{hairer2014spectral}
\@writefile{toc}{\contentsline {section}{\numberline {2}Calibrated Data Augmentation}{3}}
\newlabel{eq:da}{{1}{3}}
\newlabel{eq:missinginfo}{{2}{4}}
\newlabel{eq:Q}{{3}{4}}
\citation{tanner1987calculation,albert1993bayesian}
\citation{liu1999parameter}
\citation{meng1999seeking}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Initial example: Probit with improper prior}{5}}
\newlabel{eq:prop-marginal-probit}{{4}{5}}
\newlabel{eq:cda-probit}{{5}{5}}
\newlabel{eq:mh-criterion}{{6}{5}}
\citation{johndrow2016inefficiency}
\citation{johndrow2016inefficiency}
\newlabel{eq:varlb-probit}{{7}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Imbalanced data intercept only case}{6}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{probit_demo_intercept_proposal}{{1a}{7}}
\newlabel{sub@probit_demo_intercept_proposal}{{a}{7}}
\newlabel{probit_demo_intercept_density}{{1b}{7}}
\newlabel{sub@probit_demo_intercept_density}{{b}{7}}
\newlabel{probit_demo_intercept_posteriorsample}{{1c}{7}}
\newlabel{sub@probit_demo_intercept_posteriorsample}{{c}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Autocorrelation functions (ACFs) and kernel-smoothed density estimates for different CDA samplers in intercept-only probit model.\relax }}{7}}
\newlabel{probit_demo_intercept}{{1}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Choice of calibration parameters}{7}}
\citation{albert1993bayesian}
\citation{liu1999parameter}
\citation{albert1993bayesian}
\citation{liu1999parameter}
\citation{albert1993bayesian}
\citation{liu1999parameter}
\citation{polson2013bayesian}
\newlabel{probit_reg_trace}{{2a}{9}}
\newlabel{sub@probit_reg_trace}{{a}{9}}
\newlabel{probit_reg_acf}{{2b}{9}}
\newlabel{sub@probit_reg_acf}{{b}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Panel (a) demonstrates in traceplot and panel (b) in autocorrelation the substantial improvement in CDA by correcting the variance mis-match in probit regression with rare event data, compared with the original \citep  {albert1993bayesian} and parameter-expanded methods \citep  {liu1999parameter}.\relax }}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Logistic regression example: A second calibration approach}{9}}
\citation{cressie1981moment}
\citation{polson2013bayesian}
\citation{polson2013bayesian}
\citation{polson2013bayesian}
\citation{polson2013bayesian}
\newlabel{eq:prop-marginal-logit}{{8}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Panel (a) demonstrates in traceplot and panel (b) in autocorrelation the substantial improvement of CDA in logistic regression with rare event data, compared with the original DA \citep  {polson2013bayesian} and the M-H algorithm with multivariate normal proposal (MH-MVN).\relax }}{11}}
\newlabel{logit_random_mixing}{{3}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Theory: ergodicity and tuning}{11}}
\newlabel{eq:mh-accrat}{{9}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Co-Browsing Behavior Application}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Hierarchical Binomial Model for Estimating Co-browsing Rates}{13}}
\citation{polson2013bayesian}
\citation{carpenter2016stan}
\citation{polson2013bayesian}
\citation{polson2013bayesian}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Boxplots of the ACFs show the mixing of the $59,792$ parameters in the hierarchical binomial model, for the original DA\citep  {polson2013bayesian}, CDA and HMC.\relax }}{15}}
\newlabel{data_binomial}{{4}{15}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Parameter estimates (with 95\% credible intervals) and effective sample sizes ($T_{eff}$) of the DA, CDA and HMC in hierarchical binomial model. CDA provides parameter estimates as accurate as HMC, and is more computationally efficient than HMC.\relax }}{15}}
\newlabel{tab:binomial}{{1}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Poisson Log-Normal Model for Web Traffic Prediction}{15}}
\citation{zhou2012lognormal}
\newlabel{eq:pos_approx}{{10}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces CDA significantly improves the mixing of the parameters in the Poisson log-normal.\relax }}{17}}
\newlabel{data_poisson}{{5}{17}}
\bibdata{reference}
\bibcite{albert1993bayesian}{{1}{1993}{{Albert and Chib}}{{}}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Parameter estimates, prediction error and computing speed of the DA, CDA and HMC in Poisson regression model.\relax }}{18}}
\newlabel{table:Poisson}{{2}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{18}}
\bibcite{carpenter2016stan}{{2}{2016}{{Carpenter et~al.}}{{Carpenter, Gelman, Hoffman, Lee, Goodrich, Betancourt, Brubaker, Guo, Li, and Riddell}}}
\bibcite{conrad2015accelerating}{{3}{2015}{{Conrad et~al.}}{{Conrad, Marzouk, Pillai, and Smith}}}
\bibcite{cressie1981moment}{{4}{1981}{{Cressie et~al.}}{{Cressie, Davis, Folks, and Folks}}}
\bibcite{hairer2011asymptotic}{{5}{2011}{{Hairer et~al.}}{{Hairer, Mattingly, and Scheutzow}}}
\bibcite{hairer2014spectral}{{6}{2014}{{Hairer et~al.}}{{Hairer, Stuart, Vollmer, et~al.}}}
\bibcite{johndrow2016inefficiency}{{7}{2016}{{Johndrow et~al.}}{{Johndrow, Smith, Pillai, and Dunson}}}
\bibcite{liu1999parameter}{{8}{1999}{{Liu and Wu}}{{}}}
\bibcite{meng1999seeking}{{9}{1999}{{Meng and Van~Dyk}}{{}}}
\bibcite{meyn2012markov}{{10}{2012}{{Meyn and Tweedie}}{{}}}
\bibcite{minsker2014robust}{{11}{2014}{{Minsker et~al.}}{{Minsker, Srivastava, Lin, and Dunson}}}
\bibcite{ngai2011application}{{12}{2011}{{Ngai et~al.}}{{Ngai, Hu, Wong, Chen, and Sun}}}
\bibcite{polson2013bayesian}{{13}{2013}{{Polson et~al.}}{{Polson, Scott, and Windle}}}
\bibcite{rajaratnam2015mcmc}{{14}{2015}{{Rajaratnam and Sparks}}{{}}}
\bibcite{roberts2004general}{{15}{2004}{{Roberts et~al.}}{{Roberts, Rosenthal, et~al.}}}
\bibcite{srivastava2015wasp}{{16}{2015}{{Srivastava et~al.}}{{Srivastava, Cevher, Tran-Dinh, and Dunson}}}
\bibcite{tanner1987calculation}{{17}{1987}{{Tanner and Wong}}{{}}}
\bibcite{wakefield2007disease}{{18}{2007}{{Wakefield}}{{}}}
\bibcite{wang2010click}{{19}{2010}{{Wang et~al.}}{{Wang, Li, Cui, Zhang, and Mao}}}
\bibcite{zhou2012lognormal}{{20}{2012}{{Zhou et~al.}}{{Zhou, Li, Dunson, and Carin}}}
\bibstyle{plainnat}
\@writefile{toc}{\contentsline {section}{\numberline {6}Appendix}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Proofs}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Lemma 1}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}Theorem 1}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Goodness-of-Fit and Cross-Validation for Poisson Regression}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The posterior estimates produced by CDA is better fitted to the data and have more accurate prediction than DA.\relax }}{22}}
