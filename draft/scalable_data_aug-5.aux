\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ngai2011application}
\citation{wakefield2007disease}
\citation{wang2010click}
\citation{minsker2014robust,srivastava2015wasp,conrad2015accelerating}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{roberts2004general,meyn2012markov}
\citation{rajaratnam2015mcmc}
\citation{hairer2011asymptotic}
\citation{hairer2014spectral}
\citation{johndrow2016inefficiency}
\citation{albert1993bayesian}
\citation{polson2013bayesian}
\citation{hairer2014spectral}
\citation{tran2016adaptive}
\@writefile{toc}{\contentsline {section}{\numberline {2}Calibrated Data Augmentation}{3}{section.2}}
\newlabel{sec:cda}{{2}{3}{Calibrated Data Augmentation}{section.2}{}}
\citation{papaspiliopoulos2007general}
\citation{rubin2004multiple}
\citation{liu1994fraction}
\newlabel{eq:da}{{1}{4}{Calibrated Data Augmentation}{equation.2.1}{}}
\newlabel{eq:missinginfo}{{2}{4}{Calibrated Data Augmentation}{equation.2.2}{}}
\citation{liu1994fraction}
\newlabel{eq:Q}{{3}{5}{Calibrated Data Augmentation}{equation.2.3}{}}
\citation{roberts1994simple}
\newlabel{rem:accrat}{{1}{6}{}{remark.1}{}}
\newlabel{eq:mh-accrat}{{4}{6}{}{equation.2.4}{}}
\newlabel{rem:ergodic}{{2}{6}{Ergodicity}{remark.2}{}}
\citation{tanner1987calculation,albert1993bayesian}
\citation{johndrow2016inefficiency}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Initial example: probit with intercept only}{7}{subsection.2.1}}
\newlabel{eq:prop-marginal-probit-intercept}{{5}{7}{Initial example: probit with intercept only}{equation.2.5}{}}
\newlabel{eq:cda-probit-intercept}{{6}{8}{Initial example: probit with intercept only}{equation.2.6}{}}
\citation{tanner1987calculation,albert1993bayesian}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{probit_demo_intercept_proposal}{{1a}{9}{ACF for CDA without M-H adjustment.\relax }{figure.caption.1}{}}
\newlabel{sub@probit_demo_intercept_proposal}{{a}{9}{ACF for CDA without M-H adjustment.\relax }{figure.caption.1}{}}
\newlabel{probit_demo_intercept_density}{{1b}{9}{Posterior density estimates without M-H adjustment.\relax }{figure.caption.1}{}}
\newlabel{sub@probit_demo_intercept_density}{{b}{9}{Posterior density estimates without M-H adjustment.\relax }{figure.caption.1}{}}
\newlabel{probit_demo_intercept_posteriorsample}{{1c}{9}{ACF for CDA with M-H adjustment\relax }{figure.caption.1}{}}
\newlabel{sub@probit_demo_intercept_posteriorsample}{{c}{9}{ACF for CDA with M-H adjustment\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Autocorrelation functions (ACFs) and kernel-smoothed density estimates for different CDA samplers in intercept-only probit model.\relax }}{9}{figure.caption.1}}
\newlabel{probit_demo_intercept}{{1}{9}{Autocorrelation functions (ACFs) and kernel-smoothed density estimates for different CDA samplers in intercept-only probit model.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Specific algorithms}{9}{section.3}}
\newlabel{sec:algos}{{3}{9}{Specific algorithms}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Probit regression}{9}{subsection.3.1}}
\citation{liu1999parameter}
\citation{meng1999seeking}
\newlabel{eq:cda-probit}{{7}{10}{Probit regression}{equation.3.7}{}}
\newlabel{eq:prop-marginal-probit}{{8}{10}{Probit regression}{equation.3.8}{}}
\newlabel{eq:varlb-probit}{{9}{11}{Probit regression}{equation.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Logistic regression}{11}{subsection.3.2}}
\citation{polson2013bayesian}
\newlabel{eq:prop-marginal-logit}{{10}{12}{Logistic regression}{equation.3.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Choice of calibration parameters}{13}{subsection.3.3}}
\newlabel{sec:tuning}{{3.3}{13}{Choice of calibration parameters}{subsection.3.3}{}}
\citation{roberts2007coupling}
\citation{albert1993bayesian}
\citation{liu1999parameter}
\citation{albert1993bayesian}
\citation{liu1999parameter}
\citation{albert1993bayesian}
\citation{liu1999parameter}
\citation{polson2013bayesian}
\newlabel{probit_reg_trace}{{2a}{16}{Traceplot for the original DA, parameter expanded DA and CDA algorithms.\relax }{figure.caption.2}{}}
\newlabel{sub@probit_reg_trace}{{a}{16}{Traceplot for the original DA, parameter expanded DA and CDA algorithms.\relax }{figure.caption.2}{}}
\newlabel{probit_reg_acf}{{2b}{16}{ACF for original DA, parameter expanded DA and CDA algorithms.\relax }{figure.caption.2}{}}
\newlabel{sub@probit_reg_acf}{{b}{16}{ACF for original DA, parameter expanded DA and CDA algorithms.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Panel (a) demonstrates in traceplot and panel (b) in autocorrelation the substantial improvement in CDA by correcting the variance mis-match in probit regression with rare event data, compared with the original \citep  {albert1993bayesian} and parameter-expanded methods \citep  {liu1999parameter}.\relax }}{16}{figure.caption.2}}
\citation{polson2013bayesian}
\citation{polson2013bayesian}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Panel (a) demonstrates in traceplot and panel (b) in autocorrelation the substantial improvement of CDA in logistic regression with rare event data, compared with the original DA \citep  {polson2013bayesian} and the M-H algorithm with multivariate normal proposal (MH-MVN).\relax }}{17}{figure.caption.3}}
\newlabel{logit_random_mixing}{{3}{17}{Panel (a) demonstrates in traceplot and panel (b) in autocorrelation the substantial improvement of CDA in logistic regression with rare event data, compared with the original DA \citep {polson2013bayesian} and the M-H algorithm with multivariate normal proposal (MH-MVN).\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Co-Browsing Behavior Application}{17}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Hierarchical Binomial Model for Co-Browsing Rates}{18}{subsection.4.1}}
\citation{polson2013bayesian}
\citation{carpenter2016stan}
\citation{polson2013bayesian}
\citation{polson2013bayesian}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Boxplots of the ACFs show the mixing of the $59,792$ parameters in the hierarchical binomial model, for the original DA\citep  {polson2013bayesian}, CDA and HMC.\relax }}{20}{figure.caption.4}}
\newlabel{data_binomial}{{4}{20}{Boxplots of the ACFs show the mixing of the $59,792$ parameters in the hierarchical binomial model, for the original DA\citep {polson2013bayesian}, CDA and HMC.\relax }{figure.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Parameter estimates (with 95\% credible intervals) and computing speed (ratios among computing time, effective sample sizes $T_{eff}$ and total iterations $T$) of the DA, CDA and HMC in hierarchical binomial model. CDA provides parameter estimates as accurate as HMC, and is more computationally efficient than HMC.\relax }}{21}{table.caption.5}}
\newlabel{tab:binomial}{{1}{21}{Parameter estimates (with 95\% credible intervals) and computing speed (ratios among computing time, effective sample sizes $T_{eff}$ and total iterations $T$) of the DA, CDA and HMC in hierarchical binomial model. CDA provides parameter estimates as accurate as HMC, and is more computationally efficient than HMC.\relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Poisson Log-Normal Model for Web Traffic Prediction}{21}{subsection.4.2}}
\citation{liu1994collapsed}
\citation{zhou2012lognormal}
\newlabel{eq:pos_approx}{{11}{22}{Poisson Log-Normal Model for Web Traffic Prediction}{equation.4.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces CDA significantly improves the mixing of the parameters in the Poisson log-normal.\relax }}{25}{figure.caption.6}}
\newlabel{data_poisson}{{5}{25}{CDA significantly improves the mixing of the parameters in the Poisson log-normal.\relax }{figure.caption.6}{}}
\citation{papaspiliopoulos2007general}
\citation{liu1999parameter}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Parameter estimates, prediction error and computing speed of the DA, CDA and HMC in Poisson regression model.\relax }}{26}{table.caption.7}}
\newlabel{table:Poisson}{{2}{26}{Parameter estimates, prediction error and computing speed of the DA, CDA and HMC in Poisson regression model.\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{26}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Proofs}{27}{appendix.A}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Proof of Remark \ref  {rem:accrat}}{27}{subsection.A.1}}
\citation{roberts1994simple}
\citation{roberts1994simple}
\bibdata{reference}
\bibcite{albert1993bayesian}{{1}{1993}{{Albert and Chib}}{{Albert and Chib}}}
\bibcite{carpenter2016stan}{{2}{2016}{{Carpenter et~al.}}{{Carpenter, Gelman, Hoffman, Lee, Goodrich, Betancourt, Brubaker, Guo, Li, and Riddell}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Proof of Remark \ref  {rem:ergodic}}{28}{subsection.A.2}}
\bibcite{conrad2015accelerating}{{3}{2015}{{Conrad et~al.}}{{Conrad, Marzouk, Pillai, and Smith}}}
\bibcite{hairer2011asymptotic}{{4}{2011}{{Hairer et~al.}}{{Hairer, Mattingly, and Scheutzow}}}
\bibcite{hairer2014spectral}{{5}{2014}{{Hairer et~al.}}{{Hairer, Stuart, and Vollmer}}}
\bibcite{johndrow2016inefficiency}{{6}{2016}{{Johndrow et~al.}}{{Johndrow, Smith, Pillai, and Dunson}}}
\bibcite{liu1994collapsed}{{7}{1994a}{{Liu}}{{Liu}}}
\bibcite{liu1994fraction}{{8}{1994b}{{Liu}}{{Liu}}}
\bibcite{liu1999parameter}{{9}{1999}{{Liu and Wu}}{{Liu and Wu}}}
\bibcite{meng1999seeking}{{10}{1999}{{Meng and Van~Dyk}}{{Meng and Van~Dyk}}}
\bibcite{meyn2012markov}{{11}{2012}{{Meyn and Tweedie}}{{Meyn and Tweedie}}}
\bibcite{minsker2014robust}{{12}{2014}{{Minsker et~al.}}{{Minsker, Srivastava, Lin, and Dunson}}}
\bibcite{ngai2011application}{{13}{2011}{{Ngai et~al.}}{{Ngai, Hu, Wong, Chen, and Sun}}}
\bibcite{papaspiliopoulos2007general}{{14}{2007}{{Papaspiliopoulos et~al.}}{{Papaspiliopoulos, Roberts, and Sk{\"o}ld}}}
\bibcite{polson2013bayesian}{{15}{2013}{{Polson et~al.}}{{Polson, Scott, and Windle}}}
\bibcite{rajaratnam2015mcmc}{{16}{2015}{{Rajaratnam and Sparks}}{{Rajaratnam and Sparks}}}
\bibcite{roberts2007coupling}{{17}{2007}{{Roberts and Rosenthal}}{{Roberts and Rosenthal}}}
\bibcite{roberts2004general}{{18}{2004}{{Roberts et~al.}}{{Roberts, Rosenthal, et~al.}}}
\bibcite{roberts1994simple}{{19}{1994}{{Roberts and Smith}}{{Roberts and Smith}}}
\bibcite{rubin2004multiple}{{20}{2004}{{Rubin}}{{Rubin}}}
\bibcite{srivastava2015wasp}{{21}{2015}{{Srivastava et~al.}}{{Srivastava, Cevher, Tran-Dinh, and Dunson}}}
\bibcite{tanner1987calculation}{{22}{1987}{{Tanner and Wong}}{{Tanner and Wong}}}
\bibcite{tran2016adaptive}{{23}{2016}{{Tran et~al.}}{{Tran, Pitt, and Kohn}}}
\bibcite{wakefield2007disease}{{24}{2007}{{Wakefield}}{{Wakefield}}}
\bibcite{wang2010click}{{25}{2010}{{Wang et~al.}}{{Wang, Li, Cui, Zhang, and Mao}}}
\bibcite{zhou2012lognormal}{{26}{2012}{{Zhou et~al.}}{{Zhou, Li, Dunson, and Carin}}}
\bibstyle{chicago}
