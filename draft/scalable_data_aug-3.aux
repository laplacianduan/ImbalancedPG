\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ngai2011application}
\citation{wakefield2007disease}
\citation{wang2010click}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{minsker2014robust,srivastava2015wasp,conrad2015accelerating}
\citation{roberts2004general,meyn2012markov}
\citation{rajaratnam2015mcmc}
\citation{hairer2011asymptotic}
\citation{hairer2014spectral}
\citation{johndrow2016inefficiency}
\citation{albert1993bayesian}
\citation{polson2013bayesian}
\citation{hairer2014spectral}
\citation{tran2016adaptive}
\citation{papaspiliopoulos2007general}
\citation{rubin2004multiple}
\citation{liu1994fraction}
\@writefile{toc}{\contentsline {section}{\numberline {2}Calibrated Data Augmentation}{3}{section.2}}
\newlabel{sec:cda}{{2}{3}{Calibrated Data Augmentation}{section.2}{}}
\newlabel{eq:da}{{1}{3}{Calibrated Data Augmentation}{equation.2.1}{}}
\newlabel{eq:missinginfo}{{2}{3}{Calibrated Data Augmentation}{equation.2.2}{}}
\citation{liu1994fraction}
\newlabel{eq:Q}{{3}{4}{Calibrated Data Augmentation}{equation.2.3}{}}
\newlabel{rem:accrat}{{1}{4}{}{remark.1}{}}
\newlabel{eq:mh-accrat}{{4}{4}{}{equation.2.4}{}}
\citation{roberts1994simple}
\citation{tanner1987calculation,albert1993bayesian}
\citation{johndrow2016inefficiency}
\newlabel{rem:ergodic}{{2}{5}{Ergodicity}{remark.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Initial example: probit with intercept only}{5}{subsection.2.1}}
\newlabel{eq:prop-marginal-probit-intercept}{{5}{5}{Initial example: probit with intercept only}{equation.2.5}{}}
\newlabel{eq:cda-probit-intercept}{{6}{6}{Initial example: probit with intercept only}{equation.2.6}{}}
\citation{tanner1987calculation,albert1993bayesian}
\citation{liu1999parameter}
\citation{meng1999seeking}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{probit_demo_intercept_proposal}{{1a}{7}{ACF for CDA without M-H adjustment.\relax }{figure.caption.1}{}}
\newlabel{sub@probit_demo_intercept_proposal}{{a}{7}{ACF for CDA without M-H adjustment.\relax }{figure.caption.1}{}}
\newlabel{probit_demo_intercept_density}{{1b}{7}{Density estimates of the posterior without M-H adjustment.\relax }{figure.caption.1}{}}
\newlabel{sub@probit_demo_intercept_density}{{b}{7}{Density estimates of the posterior without M-H adjustment.\relax }{figure.caption.1}{}}
\newlabel{probit_demo_intercept_posteriorsample}{{1c}{7}{ACF for CDA with M-H adjustment\relax }{figure.caption.1}{}}
\newlabel{sub@probit_demo_intercept_posteriorsample}{{c}{7}{ACF for CDA with M-H adjustment\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Autocorrelation functions (ACFs) and kernel-smoothed density estimates for different CDA samplers in intercept-only probit model.\relax }}{7}{figure.caption.1}}
\newlabel{probit_demo_intercept}{{1}{7}{Autocorrelation functions (ACFs) and kernel-smoothed density estimates for different CDA samplers in intercept-only probit model.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Specific algorithms}{7}{section.3}}
\newlabel{sec:algos}{{3}{7}{Specific algorithms}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Probit regression}{7}{subsection.3.1}}
\newlabel{eq:cda-probit}{{7}{7}{Probit regression}{equation.3.7}{}}
\newlabel{eq:prop-marginal-probit}{{8}{7}{Probit regression}{equation.3.8}{}}
\citation{polson2013bayesian}
\newlabel{eq:varlb-probit}{{9}{8}{Probit regression}{equation.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Logistic regression}{8}{subsection.3.2}}
\citation{cressie1981moment}
\citation{polson2013bayesian}
\newlabel{eq:prop-marginal-logit}{{10}{9}{Logistic regression}{equation.3.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Choice of calibration parameters}{9}{subsection.3.3}}
\newlabel{sec:tuning}{{3.3}{9}{Choice of calibration parameters}{subsection.3.3}{}}
\citation{roberts2007coupling}
\citation{albert1993bayesian}
\citation{liu1999parameter}
\citation{albert1993bayesian}
\citation{liu1999parameter}
\citation{albert1993bayesian}
\citation{liu1999parameter}
\citation{polson2013bayesian}
\citation{polson2013bayesian}
\citation{polson2013bayesian}
\newlabel{probit_reg_trace}{{2a}{11}{Traceplot for the original DA, parameter expanded DA and CDA algorithms.\relax }{figure.caption.2}{}}
\newlabel{sub@probit_reg_trace}{{a}{11}{Traceplot for the original DA, parameter expanded DA and CDA algorithms.\relax }{figure.caption.2}{}}
\newlabel{probit_reg_acf}{{2b}{11}{ACF for original DA, parameter expanded DA and CDA algorithms.\relax }{figure.caption.2}{}}
\newlabel{sub@probit_reg_acf}{{b}{11}{ACF for original DA, parameter expanded DA and CDA algorithms.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Panel (a) demonstrates in traceplot and panel (b) in autocorrelation the substantial improvement in CDA by correcting the variance mis-match in probit regression with rare event data, compared with the original \citep  {albert1993bayesian} and parameter-expanded methods \citep  {liu1999parameter}.\relax }}{11}{figure.caption.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Panel (a) demonstrates in traceplot and panel (b) in autocorrelation the substantial improvement of CDA in logistic regression with rare event data, compared with the original DA \citep  {polson2013bayesian} and the M-H algorithm with multivariate normal proposal (MH-MVN).\relax }}{12}{figure.caption.3}}
\newlabel{logit_random_mixing}{{3}{12}{Panel (a) demonstrates in traceplot and panel (b) in autocorrelation the substantial improvement of CDA in logistic regression with rare event data, compared with the original DA \citep {polson2013bayesian} and the M-H algorithm with multivariate normal proposal (MH-MVN).\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Co-Browsing Behavior Application}{12}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Hierarchical Binomial Model for Estimating Co-browsing Rates}{12}{subsection.4.1}}
\citation{polson2013bayesian}
\citation{carpenter2016stan}
\citation{polson2013bayesian}
\citation{polson2013bayesian}
\citation{liu1994collapsed}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Boxplots of the ACFs show the mixing of the $59,792$ parameters in the hierarchical binomial model, for the original DA\citep  {polson2013bayesian}, CDA and HMC.\relax }}{14}{figure.caption.4}}
\newlabel{data_binomial}{{4}{14}{Boxplots of the ACFs show the mixing of the $59,792$ parameters in the hierarchical binomial model, for the original DA\citep {polson2013bayesian}, CDA and HMC.\relax }{figure.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Parameter estimates (with 95\% credible intervals) and computing speed (ratios among computing time, effective sample sizes $T_{eff}$ and total iterations $T$) of the DA, CDA and HMC in hierarchical binomial model. CDA provides parameter estimates as accurate as HMC, and is more computationally efficient than HMC.\relax }}{14}{table.caption.5}}
\newlabel{tab:binomial}{{1}{14}{Parameter estimates (with 95\% credible intervals) and computing speed (ratios among computing time, effective sample sizes $T_{eff}$ and total iterations $T$) of the DA, CDA and HMC in hierarchical binomial model. CDA provides parameter estimates as accurate as HMC, and is more computationally efficient than HMC.\relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Poisson Log-Normal Model for Web Traffic Prediction}{14}{subsection.4.2}}
\citation{zhou2012lognormal}
\newlabel{eq:pos_approx}{{11}{15}{Poisson Log-Normal Model for Web Traffic Prediction}{equation.4.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces CDA significantly improves the mixing of the parameters in the Poisson log-normal.\relax }}{16}{figure.caption.6}}
\newlabel{data_poisson}{{5}{16}{CDA significantly improves the mixing of the parameters in the Poisson log-normal.\relax }{figure.caption.6}{}}
\citation{papaspiliopoulos2007general}
\citation{liu1999parameter}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Parameter estimates, prediction error and computing speed of the DA, CDA and HMC in Poisson regression model.\relax }}{17}{table.caption.7}}
\newlabel{table:Poisson}{{2}{17}{Parameter estimates, prediction error and computing speed of the DA, CDA and HMC in Poisson regression model.\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{17}{section.5}}
\citation{roberts1994simple}
\citation{roberts1994simple}
\bibdata{reference}
\bibcite{albert1993bayesian}{{1}{1993}{{Albert and Chib}}{{}}}
\bibcite{carpenter2016stan}{{2}{2016}{{Carpenter et~al.}}{{Carpenter, Gelman, Hoffman, Lee, Goodrich, Betancourt, Brubaker, Guo, Li, and Riddell}}}
\bibcite{conrad2015accelerating}{{3}{2015}{{Conrad et~al.}}{{Conrad, Marzouk, Pillai, and Smith}}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Proofs}{18}{appendix.A}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Proof of Remark \ref  {rem:accrat}}{18}{subsection.A.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Proof of Remark \ref  {rem:ergodic}}{18}{subsection.A.2}}
\bibcite{cressie1981moment}{{4}{1981}{{Cressie et~al.}}{{Cressie, Davis, Folks, and Folks}}}
\bibcite{hairer2011asymptotic}{{5}{2011}{{Hairer et~al.}}{{Hairer, Mattingly, and Scheutzow}}}
\bibcite{hairer2014spectral}{{6}{2014}{{Hairer et~al.}}{{Hairer, Stuart, Vollmer, et~al.}}}
\bibcite{johndrow2016inefficiency}{{7}{2016}{{Johndrow et~al.}}{{Johndrow, Smith, Pillai, and Dunson}}}
\bibcite{liu1994collapsed}{{8}{1994{}}{{Liu}}{{}}}
\bibcite{liu1994fraction}{{9}{1994{}}{{Liu}}{{}}}
\bibcite{liu1999parameter}{{10}{1999}{{Liu and Wu}}{{}}}
\bibcite{meng1999seeking}{{11}{1999}{{Meng and Van~Dyk}}{{}}}
\bibcite{meyn2012markov}{{12}{2012}{{Meyn and Tweedie}}{{}}}
\bibcite{minsker2014robust}{{13}{2014}{{Minsker et~al.}}{{Minsker, Srivastava, Lin, and Dunson}}}
\bibcite{ngai2011application}{{14}{2011}{{Ngai et~al.}}{{Ngai, Hu, Wong, Chen, and Sun}}}
\bibcite{papaspiliopoulos2007general}{{15}{2007}{{Papaspiliopoulos et~al.}}{{Papaspiliopoulos, Roberts, and Sk{\"o}ld}}}
\bibcite{polson2013bayesian}{{16}{2013}{{Polson et~al.}}{{Polson, Scott, and Windle}}}
\bibcite{rajaratnam2015mcmc}{{17}{2015}{{Rajaratnam and Sparks}}{{}}}
\bibcite{roberts2007coupling}{{18}{2007}{{Roberts and Rosenthal}}{{}}}
\bibcite{roberts1994simple}{{19}{1994}{{Roberts and Smith}}{{}}}
\bibcite{roberts2004general}{{20}{2004}{{Roberts et~al.}}{{Roberts, Rosenthal, et~al.}}}
\bibcite{rubin2004multiple}{{21}{2004}{{Rubin}}{{}}}
\bibcite{srivastava2015wasp}{{22}{2015}{{Srivastava et~al.}}{{Srivastava, Cevher, Tran-Dinh, and Dunson}}}
\bibcite{tanner1987calculation}{{23}{1987}{{Tanner and Wong}}{{}}}
\bibcite{tran2016adaptive}{{24}{2016}{{Tran et~al.}}{{Tran, Pitt, and Kohn}}}
\bibcite{wakefield2007disease}{{25}{2007}{{Wakefield}}{{}}}
\bibcite{wang2010click}{{26}{2010}{{Wang et~al.}}{{Wang, Li, Cui, Zhang, and Mao}}}
\bibcite{zhou2012lognormal}{{27}{2012}{{Zhou et~al.}}{{Zhou, Li, Dunson, and Carin}}}
\bibstyle{plainnat}
